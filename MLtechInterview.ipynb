{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yaxTV5iyhQ82"
   },
   "source": [
    "# ML Tech Interview\n",
    "\n",
    "Hello and welcome to the Machine Learning Tech Interview. This interview will be divided in two parts: the theoretical part and the practical/coding part. \n",
    "\n",
    "### **I will review only the scripts that will be sent (by pull request on this repo) by 5:00 pm on Friday**\n",
    "\n",
    "Good Luck!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HQjWqn__hQ85"
   },
   "source": [
    "## Theoretical Part\n",
    "\n",
    "Please answer the following questions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-0X1MRGNhQ86"
   },
   "source": [
    "#### What are the assumptions of a linear model (or any other type of model)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c9rLLjNphQ86"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nLinearity: The relationship between X and the mean of Y is linear.\\n??: The mean of residuals is zero (or very close to it).\\nHomoscedasticity: The variance of residual is the same for any value of X.\\n??: No autocorrelation of residuals.\\n??: The X variables and residuals are uncorrelated.\\nIndependence: Observations are independent of each other.\\n?? No perfect multicollinearity.\\nNormality: For any fixed value of X, Y is normally distributed.\\n??: Normality of residuals.\\n??: The number of observations must be greater than number of Xs.\\n??: The variability in X values is positive.\\n??: The regression model is correctly specified.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Linearity: The relationship between X and the mean of Y is linear.\n",
    "??: The mean of residuals is zero (or very close to it).\n",
    "Homoscedasticity: The variance of residual is the same for any value of X.\n",
    "??: No autocorrelation of residuals.\n",
    "??: The X variables and residuals are uncorrelated.\n",
    "Independence: Observations are independent of each other.\n",
    "?? No perfect multicollinearity.\n",
    "Normality: For any fixed value of X, Y is normally distributed.\n",
    "??: Normality of residuals.\n",
    "??: The number of observations must be greater than number of Xs.\n",
    "??: The variability in X values is positive.\n",
    "??: The regression model is correctly specified.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XWNx7P4HhQ8_"
   },
   "source": [
    "#### What’s the difference between K Nearest Neighbor and K-means Clustering?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hQ16LsGthQ8_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nK Nearest Neighbor (KNN) is:\\n- supervised \\n- for classification or regression \\n- requires labeled data to train on\\n\\nK-means Clustering is:\\n- unsupervised \\n- for clustering\\n- iteratively partitions data points into clusters\\n\\nthe k value represents a different parameter as well.\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "K Nearest Neighbor (KNN) is:\n",
    "- supervised \n",
    "- for classification or regression \n",
    "- requires labeled data to train on\n",
    "\n",
    "K-means Clustering is:\n",
    "- unsupervised \n",
    "- for clustering\n",
    "- iteratively partitions data points into clusters\n",
    "\n",
    "the k value represents a different parameter as well.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iDDPRfBRhQ9B"
   },
   "source": [
    "#### How do you address overfitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h1TyBsLwhQ9D"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nOverfitting is the production of a model that corresponds too closely to a particular set of\\ndata, and may therefore fail to predict additional data. This usually occurs when a model has\\ntoo many features for the amount of data. Overfitting can be detected when our model does \\nmuch better on the training set than on the test set. There are several ways to address \\noverfitting:\\n\\n- Feature selection: dropping columns.\\n- Dimensionality reduction: techniques such as Principal Component Analysis (PCA) reduce the\\ndimensions of your feature space, hence you have fewer relationships between variables to \\nconsider and you are less likely to overfit your model.\\n- More data points\\n- Cross validation\\n- Regularization: these are techniques that attempt to simplify the model such as adding \\npenalties to the cost function.\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Overfitting is the production of a model that corresponds too closely to a particular set of\n",
    "data, and may therefore fail to predict additional data. This usually occurs when a model has\n",
    "too many features for the amount of data. Overfitting can be detected when our model does \n",
    "much better on the training set than on the test set. There are several ways to address \n",
    "overfitting:\n",
    "\n",
    "- Feature selection: dropping columns.\n",
    "- Dimensionality reduction: techniques such as Principal Component Analysis (PCA) reduce the\n",
    "dimensions of your feature space, hence you have fewer relationships between variables to \n",
    "consider and you are less likely to overfit your model.\n",
    "- More data points\n",
    "- Cross validation\n",
    "- Regularization: these are techniques that attempt to simplify the model such as adding \n",
    "penalties to the cost function.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0dInW-RQhQ9G"
   },
   "source": [
    "#### Explain Naive Bayes algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U76IQ8xdhQ9H"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Naive Bayes (NB) is a classification algorithm. \n",
    "\n",
    "It asks the question: “Given these features, does this measurement belong to class A or B?”,\n",
    "then answers it by taking the proportion of all previous measurements with the same features\n",
    "belonging to class A and multiplying it by the the proportion of all measurements in class A.\n",
    "If this number is bigger than the corresponding calculation for class B we say the \n",
    "measurement belongs in class A. \n",
    "\n",
    "Since we're assuming that all features are independent of each other, we can take each \n",
    "feature separately and determine the proportion of previous measurements that belong to \n",
    "class A that have the same value for this feature. Then we repeat this process to every other\n",
    "feature, and take its product, before finally multiplying it by the proportion of class A in \n",
    "the dataset. If this number is larger than when we do the corresponding calculation for class\n",
    "B, then it belongs in class A.\n",
    "\n",
    "This assumption of independence of features (which is almost never true), is what allows us \n",
    "to not need to rely on exact duplicates from previously measured points, which would make \n",
    "practically useless — as it would only be able to classify these duplicates and nothing more.\n",
    "\n",
    "That's why it's called 'naive'.\n",
    "\n",
    "The great thing about NB is that this \"naive assumption\" actually tends to help the \n",
    "classification. The reason for this is that assuming two features are independent (when \n",
    "they're actually dependent), implies we're doubly-counting evidence. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-UsLyyonHYwN"
   },
   "source": [
    "#### When do you use an AUC-ROC score? What kind of information can you gather from it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jp5SotUdHrZf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6gMzc684hQ9J"
   },
   "source": [
    "#### What is cross validation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7yhBiZyJhQ9K"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wqEQlGL2hQ9L"
   },
   "source": [
    "#### What are confounding variables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r-8POEd6hQ9M"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9ixSZaNdhQ9P"
   },
   "source": [
    "#### If an important metric for our company stopped appearing in our data source, how would you investigate the causes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KOPUF1i3hQ9Q"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ko6vUaXshQ9S"
   },
   "source": [
    "## Practical Machine Learning\n",
    "\n",
    "In this challenge, you will showcase your knowledge in feature engineering, dimensionality reduction, model selection and evaluation, hyperparameter tuning, and any other techniques of machine learning.\n",
    "\n",
    "There isn't a correct solution to this challenge. All we would like to learn is your thinking process that demonstrates your knowledge, experience, and creativity in developing machine learning models. Therefore, in addition to developing the model and optimizing its performance, you should also elaborate your thinking process and justify your decisions thoughout the iterative problem-solving process.\n",
    "\n",
    "The suggested time to spend on this challenge is 90-120 minutes. If you don't have time to finish all the tasks you plan to do, simply document the to-dos at the end of your response.\n",
    "\n",
    "#### Instructions:\n",
    "\n",
    "- Download the housing prices data set (housing_prices.csv). The data is big enough to showcase your thoughts but not so that processing power will be a problem.\n",
    "- Using Python, analyze the features and determine which feature set to select for modeling.\n",
    "- Train and cross validate several regression models, attempting to accurately predict the SalePrice target variable.\n",
    "- Evaluate all models and show comparison of performance metrics.\n",
    "- State your thoughts on model performance, which model(s) you would select, and why.\n",
    "\n",
    "#### Deliverables Checklist:\n",
    "\n",
    "- Python code.\n",
    "- Your thinking process.\n",
    "- The features selected for machine learning.\n",
    "- The results (e.g., performance metrics) of your selected model(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3moKc9n4hQ9T"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MLtechInterview.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
